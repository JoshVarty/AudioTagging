{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficient Net\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from fastai.vision import Path, ImageList, Learner, imagenet_stats, cnn_learner, get_transforms, DatasetType, models, load_learner, fbeta\n",
    "import sklearn.metrics\n",
    "from functools import partial\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fddbca92e30>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 06_EfficientNet__folds5\n"
     ]
    }
   ],
   "source": [
    "NFOLDS = 5\n",
    "script_name = os.path.basename('06_EfficientNet').split('.')[0]\n",
    "MODEL_NAME = \"{0}__folds{1}\".format(script_name, NFOLDS)\n",
    "print(\"Model: {}\".format(MODEL_NAME))\n",
    "\n",
    "# Make required folders if they're not already present\n",
    "directories = ['kfolds', 'model_predictions', 'model_source']\n",
    "for directory in directories:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overall_lwlrap_sklearn(scores, truth):\n",
    "    # Calculate the overall lwlrap using sklearn.metrics.lrap.\n",
    "    # sklearn doesn't correctly apply weighting to samples with no labels, so just skip them.\n",
    "    overall_lwlrap = sklearn.metrics.label_ranking_average_precision_score(truth > 0, scores)\n",
    "    \n",
    "    return torch.Tensor([overall_lwlrap])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = Path('data')\n",
    "WORK = Path('work')\n",
    "\n",
    "CSV_TRN_MERGED = DATA/'train_merged.csv'\n",
    "CSV_SUBMISSION = DATA/'sample_submission.csv'\n",
    "\n",
    "TRN_CURATED = DATA/'train_curated'\n",
    "TRN_NOISY = DATA/'train_noisy'\n",
    "\n",
    "IMG_TRN_CURATED = WORK/'image/trn_curated'\n",
    "IMG_TRN_NOISY = WORK/'image/trn_noisy'\n",
    "IMG_TEST = WORK/'image/test'\n",
    "\n",
    "TEST = DATA/'test'\n",
    "\n",
    "train = pd.read_csv(DATA/'train_curated.csv')\n",
    "test = pd.read_csv(DATA/'sample_submission.csv')\n",
    "train_noisy = pd.read_csv(DATA/'train_noisy.csv')\n",
    "train_merged = pd.read_csv(DATA/'train_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train['fname']\n",
    "y = train['labels'].apply(lambda f: f.split(','))\n",
    "y_noisy = train_noisy['labels'].apply(lambda f: f.split(','))\n",
    "transformed_y = MultiLabelBinarizer().fit_transform(y)\n",
    "transformed_y_noisy = MultiLabelBinarizer().fit_transform(y_noisy)\n",
    "filenames = train['fname'].values\n",
    "filenames = filenames.reshape(-1, 1)\n",
    "\n",
    "oof_preds = np.zeros((len(train), 80))\n",
    "test_preds = np.zeros((len(test), 80))\n",
    "\n",
    "tfms = get_transforms(do_flip=True, max_rotate=0, max_lighting=0.1, max_zoom=0, max_warp=0.)\n",
    "\n",
    "mskf = MultilabelStratifiedKFold(n_splits=5, random_state=4, shuffle=True)\n",
    "_, val_index = next(mskf.split(X, transformed_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways of getting the EfficientNet in this implementation. The first is `from_pretrained` (to get the full network pretrained on ImageNet) and the second is `from_name` to get only the body of the network. I didn't manage to append a fastai custom_head on the latter so I changed a little the code of the first technique : \n",
    "\n",
    "    - I changed the number of classes from 1000 to 80 to suit our task\n",
    "    - Commented the `load_pretrained_weights()` part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This file contains helper functions for building the model and for loading model parameters.\n",
    "These helper functions are built to mirror those in the official TensorFlow implementation.\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import math\n",
    "import collections\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils import model_zoo\n",
    "\n",
    "\n",
    "########################################################################\n",
    "############### HELPERS FUNCTIONS FOR MODEL ARCHITECTURE ###############\n",
    "########################################################################\n",
    "\n",
    "\n",
    "# Parameters for the entire model (stem, all blocks, and head)\n",
    "GlobalParams = collections.namedtuple('GlobalParams', [\n",
    "    'batch_norm_momentum', 'batch_norm_epsilon', 'dropout_rate',\n",
    "    'num_classes', 'width_coefficient', 'depth_coefficient',\n",
    "    'depth_divisor', 'min_depth', 'drop_connect_rate',])\n",
    "\n",
    "\n",
    "# Parameters for an individual model block\n",
    "BlockArgs = collections.namedtuple('BlockArgs', [\n",
    "    'kernel_size', 'num_repeat', 'input_filters', 'output_filters',\n",
    "    'expand_ratio', 'id_skip', 'stride', 'se_ratio'])\n",
    "\n",
    "\n",
    "# Change namedtuple defaults\n",
    "GlobalParams.__new__.__defaults__ = (None,) * len(GlobalParams._fields)\n",
    "BlockArgs.__new__.__defaults__ = (None,) * len(BlockArgs._fields)\n",
    "\n",
    "\n",
    "def relu_fn(x):\n",
    "    \"\"\" Swish activation function \"\"\"\n",
    "    return x * torch.sigmoid(x)\n",
    "\n",
    "\n",
    "def round_filters(filters, global_params):\n",
    "    \"\"\" Calculate and round number of filters based on depth multiplier. \"\"\"\n",
    "    multiplier = global_params.width_coefficient\n",
    "    if not multiplier:\n",
    "        return filters\n",
    "    divisor = global_params.depth_divisor\n",
    "    min_depth = global_params.min_depth\n",
    "    filters *= multiplier\n",
    "    min_depth = min_depth or divisor\n",
    "    new_filters = max(min_depth, int(filters + divisor / 2) // divisor * divisor)\n",
    "    if new_filters < 0.9 * filters:  # prevent rounding by more than 10%\n",
    "        new_filters += divisor\n",
    "    return int(new_filters)\n",
    "\n",
    "\n",
    "def round_repeats(repeats, global_params):\n",
    "    \"\"\" Round number of filters based on depth multiplier. \"\"\"\n",
    "    multiplier = global_params.depth_coefficient\n",
    "    if not multiplier:\n",
    "        return repeats\n",
    "    return int(math.ceil(multiplier * repeats))\n",
    "\n",
    "\n",
    "def drop_connect(inputs, p, training):\n",
    "    \"\"\" Drop connect. \"\"\"\n",
    "    if not training: return inputs\n",
    "    batch_size = inputs.shape[0]\n",
    "    keep_prob = 1 - p\n",
    "    random_tensor = keep_prob\n",
    "    random_tensor += torch.rand([batch_size, 1, 1, 1], dtype=inputs.dtype)  # uniform [0,1)\n",
    "    binary_tensor = torch.floor(random_tensor)\n",
    "    output = inputs / keep_prob * binary_tensor\n",
    "    return output\n",
    "\n",
    "\n",
    "class Conv2dSamePadding(nn.Conv2d):\n",
    "    \"\"\" 2D Convolutions like TensorFlow \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, dilation=1, groups=1, bias=True):\n",
    "        super().__init__(in_channels, out_channels, kernel_size, stride, 0, dilation, groups, bias)\n",
    "        self.stride = self.stride if len(self.stride) == 2 else [self.stride[0]]*2\n",
    "\n",
    "    def forward(self, x):\n",
    "        ih, iw = x.size()[-2:]\n",
    "        kh, kw = self.weight.size()[-2:]\n",
    "        sh, sw = self.stride\n",
    "        oh, ow = math.ceil(ih / sh), math.ceil(iw / sw)\n",
    "        pad_h = max((oh - 1) * self.stride[0] + (kh - 1) * self.dilation[0] + 1 - ih, 0)\n",
    "        pad_w = max((ow - 1) * self.stride[1] + (kw - 1) * self.dilation[1] + 1 - iw, 0)\n",
    "        if pad_h > 0 or pad_w > 0:\n",
    "            x = F.pad(x, [pad_w//2, pad_w - pad_w//2, pad_h//2, pad_h - pad_h//2])\n",
    "        return F.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
    "\n",
    "\n",
    "########################################################################\n",
    "############## HELPERS FUNCTIONS FOR LOADING MODEL PARAMS ##############\n",
    "########################################################################\n",
    "\n",
    "\n",
    "def efficientnet_params(model_name):\n",
    "    \"\"\" Map EfficientNet model name to parameter coefficients. \"\"\"\n",
    "    params_dict = {\n",
    "        # Coefficients:   width,depth,res,dropout\n",
    "        'efficientnet-b0': (1.0, 1.0, 224, 0.2),\n",
    "        'efficientnet-b1': (1.0, 1.1, 240, 0.2),\n",
    "        'efficientnet-b2': (1.1, 1.2, 260, 0.3),\n",
    "        'efficientnet-b3': (1.2, 1.4, 300, 0.3),\n",
    "        'efficientnet-b4': (1.4, 1.8, 380, 0.4),\n",
    "        'efficientnet-b5': (1.6, 2.2, 456, 0.4),\n",
    "        'efficientnet-b6': (1.8, 2.6, 528, 0.5),\n",
    "        'efficientnet-b7': (2.0, 3.1, 600, 0.5),\n",
    "    }\n",
    "    return params_dict[model_name]\n",
    "\n",
    "\n",
    "class BlockDecoder(object):\n",
    "    \"\"\" Block Decoder for readability, straight from the official TensorFlow repository \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def _decode_block_string(block_string):\n",
    "        \"\"\" Gets a block through a string notation of arguments. \"\"\"\n",
    "        assert isinstance(block_string, str)\n",
    "\n",
    "        ops = block_string.split('_')\n",
    "        options = {}\n",
    "        for op in ops:\n",
    "            splits = re.split(r'(\\d.*)', op)\n",
    "            if len(splits) >= 2:\n",
    "                key, value = splits[:2]\n",
    "                options[key] = value\n",
    "\n",
    "        # Check stride\n",
    "        assert (('s' in options and len(options['s']) == 1) or\n",
    "                (len(options['s']) == 2 and options['s'][0] == options['s'][1]))\n",
    "\n",
    "        return BlockArgs(\n",
    "            kernel_size=int(options['k']),\n",
    "            num_repeat=int(options['r']),\n",
    "            input_filters=int(options['i']),\n",
    "            output_filters=int(options['o']),\n",
    "            expand_ratio=int(options['e']),\n",
    "            id_skip=('noskip' not in block_string),\n",
    "            se_ratio=float(options['se']) if 'se' in options else None,\n",
    "            stride=[int(options['s'][0])])\n",
    "\n",
    "    @staticmethod\n",
    "    def _encode_block_string(block):\n",
    "        \"\"\"Encodes a block to a string.\"\"\"\n",
    "        args = [\n",
    "            'r%d' % block.num_repeat,\n",
    "            'k%d' % block.kernel_size,\n",
    "            's%d%d' % (block.strides[0], block.strides[1]),\n",
    "            'e%s' % block.expand_ratio,\n",
    "            'i%d' % block.input_filters,\n",
    "            'o%d' % block.output_filters\n",
    "        ]\n",
    "        if 0 < block.se_ratio <= 1:\n",
    "            args.append('se%s' % block.se_ratio)\n",
    "        if block.id_skip is False:\n",
    "            args.append('noskip')\n",
    "        return '_'.join(args)\n",
    "\n",
    "    @staticmethod\n",
    "    def decode(string_list):\n",
    "        \"\"\"\n",
    "        Decodes a list of string notations to specify blocks inside the network.\n",
    "        :param string_list: a list of strings, each string is a notation of block\n",
    "        :return: a list of BlockArgs namedtuples of block args\n",
    "        \"\"\"\n",
    "        assert isinstance(string_list, list)\n",
    "        blocks_args = []\n",
    "        for block_string in string_list:\n",
    "            blocks_args.append(BlockDecoder._decode_block_string(block_string))\n",
    "        return blocks_args\n",
    "\n",
    "    @staticmethod\n",
    "    def encode(blocks_args):\n",
    "        \"\"\"\n",
    "        Encodes a list of BlockArgs to a list of strings.\n",
    "        :param blocks_args: a list of BlockArgs namedtuples of block args\n",
    "        :return: a list of strings, each string is a notation of block\n",
    "        \"\"\"\n",
    "        block_strings = []\n",
    "        for block in blocks_args:\n",
    "            block_strings.append(BlockDecoder._encode_block_string(block))\n",
    "        return block_strings\n",
    "\n",
    "\n",
    "def efficientnet(width_coefficient=None, depth_coefficient=None,\n",
    "                 dropout_rate=0.2, drop_connect_rate=0.2):\n",
    "    \"\"\" Creates a efficientnet model. \"\"\"\n",
    "\n",
    "    blocks_args = [\n",
    "        'r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25',\n",
    "        'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25',\n",
    "        'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25',\n",
    "        'r1_k3_s11_e6_i192_o320_se0.25',\n",
    "    ]\n",
    "    blocks_args = BlockDecoder.decode(blocks_args)\n",
    "\n",
    "    global_params = GlobalParams(\n",
    "        batch_norm_momentum=0.99,\n",
    "        batch_norm_epsilon=1e-3,\n",
    "        dropout_rate=dropout_rate,\n",
    "        drop_connect_rate=drop_connect_rate,\n",
    "        # data_format='channels_last',  # removed, this is always true in PyTorch\n",
    "        num_classes=80,\n",
    "        width_coefficient=width_coefficient,\n",
    "        depth_coefficient=depth_coefficient,\n",
    "        depth_divisor=8,\n",
    "        min_depth=None\n",
    "    )\n",
    "\n",
    "    return blocks_args, global_params\n",
    "\n",
    "\n",
    "def get_model_params(model_name, override_params):\n",
    "    \"\"\" Get the block args and global params for a given model \"\"\"\n",
    "    if model_name.startswith('efficientnet'):\n",
    "        w, d, _, p = efficientnet_params(model_name)\n",
    "        # note: all models have drop connect rate = 0.2\n",
    "        blocks_args, global_params = efficientnet(width_coefficient=w, depth_coefficient=d, dropout_rate=p)\n",
    "    else:\n",
    "        raise NotImplementedError('model name is not pre-defined: %s' % model_name)\n",
    "    if override_params:\n",
    "        # ValueError will be raised here if override_params has fields not included in global_params.\n",
    "        global_params = global_params._replace(**override_params)\n",
    "    return blocks_args, global_params\n",
    "\n",
    "\n",
    "url_map = {\n",
    "    'efficientnet-b0': 'http://storage.googleapis.com/public-models/efficientnet-b0-08094119.pth',\n",
    "    'efficientnet-b1': 'http://storage.googleapis.com/public-models/efficientnet-b1-dbc7070a.pth',\n",
    "    'efficientnet-b2': 'http://storage.googleapis.com/public-models/efficientnet-b2-27687264.pth',\n",
    "    'efficientnet-b3': 'http://storage.googleapis.com/public-models/efficientnet-b3-c8376fa2.pth',\n",
    "}\n",
    "\n",
    "def load_pretrained_weights(model, model_name):\n",
    "    \"\"\" Loads pretrained weights, and downloads if loading for the first time. \"\"\"\n",
    "    state_dict = model_zoo.load_url(url_map[model_name])\n",
    "    model.load_state_dict(state_dict)\n",
    "    print('Loaded pretrained weights for {}'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class MBConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Mobile Inverted Residual Bottleneck Block\n",
    "    Args:\n",
    "        block_args (namedtuple): BlockArgs, see above\n",
    "        global_params (namedtuple): GlobalParam, see above\n",
    "    Attributes:\n",
    "        has_se (bool): Whether the block contains a Squeeze and Excitation layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, block_args, global_params):\n",
    "        super().__init__()\n",
    "        self._block_args = block_args\n",
    "        self._bn_mom = 1 - global_params.batch_norm_momentum\n",
    "        self._bn_eps = global_params.batch_norm_epsilon\n",
    "        self.has_se = (self._block_args.se_ratio is not None) and (0 < self._block_args.se_ratio <= 1)\n",
    "        self.id_skip = block_args.id_skip  # skip connection and drop connect\n",
    "\n",
    "        # Expansion phase\n",
    "        inp = self._block_args.input_filters  # number of input channels\n",
    "        oup = self._block_args.input_filters * self._block_args.expand_ratio  # number of output channels\n",
    "        if self._block_args.expand_ratio != 1:\n",
    "            self._expand_conv = Conv2dSamePadding(in_channels=inp, out_channels=oup, kernel_size=1, bias=False)\n",
    "            self._bn0 = nn.BatchNorm2d(num_features=oup, momentum=self._bn_mom, eps=self._bn_eps)\n",
    "\n",
    "        # Depthwise convolution phase\n",
    "        k = self._block_args.kernel_size\n",
    "        s = self._block_args.stride\n",
    "        self._depthwise_conv = Conv2dSamePadding(\n",
    "            in_channels=oup, out_channels=oup, groups=oup,  # groups makes it depthwise\n",
    "            kernel_size=k, stride=s, bias=False)\n",
    "        self._bn1 = nn.BatchNorm2d(num_features=oup, momentum=self._bn_mom, eps=self._bn_eps)\n",
    "\n",
    "        # Squeeze and Excitation layer, if desired\n",
    "        if self.has_se:\n",
    "            num_squeezed_channels = max(1, int(self._block_args.input_filters * self._block_args.se_ratio))\n",
    "            self._se_reduce = Conv2dSamePadding(in_channels=oup, out_channels=num_squeezed_channels, kernel_size=1)\n",
    "            self._se_expand = Conv2dSamePadding(in_channels=num_squeezed_channels, out_channels=oup, kernel_size=1)\n",
    "\n",
    "        # Output phase\n",
    "        final_oup = self._block_args.output_filters\n",
    "        self._project_conv = Conv2dSamePadding(in_channels=oup, out_channels=final_oup, kernel_size=1, bias=False)\n",
    "        self._bn2 = nn.BatchNorm2d(num_features=final_oup, momentum=self._bn_mom, eps=self._bn_eps)\n",
    "\n",
    "    def forward(self, inputs, drop_connect_rate=None):\n",
    "        \"\"\"\n",
    "        :param inputs: input tensor\n",
    "        :param drop_connect_rate: drop connect rate (float, between 0 and 1)\n",
    "        :return: output of block\n",
    "        \"\"\"\n",
    "\n",
    "        # Expansion and Depthwise Convolution\n",
    "        x = inputs\n",
    "        if self._block_args.expand_ratio != 1:\n",
    "            x = relu_fn(self._bn0(self._expand_conv(inputs)))\n",
    "        x = relu_fn(self._bn1(self._depthwise_conv(x)))\n",
    "\n",
    "        # Squeeze and Excitation\n",
    "        if self.has_se:\n",
    "            x_squeezed = F.adaptive_avg_pool2d(x, 1)\n",
    "            x_squeezed = self._se_expand(relu_fn(self._se_reduce(x_squeezed)))\n",
    "            x = torch.sigmoid(x_squeezed) * x\n",
    "\n",
    "        x = self._bn2(self._project_conv(x))\n",
    "\n",
    "        # Skip connection and drop connect\n",
    "        input_filters, output_filters = self._block_args.input_filters, self._block_args.output_filters\n",
    "        if self.id_skip and self._block_args.stride == 1 and input_filters == output_filters:\n",
    "            if drop_connect_rate:\n",
    "                x = drop_connect(x, p=drop_connect_rate, training=self.training)\n",
    "            x = x + inputs  # skip connection\n",
    "        return x\n",
    "\n",
    "\n",
    "class EfficientNet(nn.Module):\n",
    "    \"\"\"\n",
    "    An EfficientNet model. Most easily loaded with the .from_name or .from_pretrained methods\n",
    "    Args:\n",
    "        blocks_args (list): A list of BlockArgs to construct blocks\n",
    "        global_params (namedtuple): A set of GlobalParams shared between blocks\n",
    "    Example:\n",
    "        model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, blocks_args=None, global_params=None):\n",
    "        super().__init__()\n",
    "        assert isinstance(blocks_args, list), 'blocks_args should be a list'\n",
    "        assert len(blocks_args) > 0, 'block args must be greater than 0'\n",
    "        self._global_params = global_params\n",
    "        self._blocks_args = blocks_args\n",
    "\n",
    "        # Batch norm parameters\n",
    "        bn_mom = 1 - self._global_params.batch_norm_momentum\n",
    "        bn_eps = self._global_params.batch_norm_epsilon\n",
    "\n",
    "        # Stem\n",
    "        in_channels = 3  # rgb\n",
    "        out_channels = round_filters(32, self._global_params)  # number of output channels\n",
    "        self._conv_stem = Conv2dSamePadding(in_channels, out_channels, kernel_size=3, stride=2, bias=False)\n",
    "        self._bn0 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n",
    "\n",
    "        # Build blocks\n",
    "        self._blocks = nn.ModuleList([])\n",
    "        for block_args in self._blocks_args:\n",
    "\n",
    "            # Update block input and output filters based on depth multiplier.\n",
    "            block_args = block_args._replace(\n",
    "                input_filters=round_filters(block_args.input_filters, self._global_params),\n",
    "                output_filters=round_filters(block_args.output_filters, self._global_params),\n",
    "                num_repeat=round_repeats(block_args.num_repeat, self._global_params)\n",
    "            )\n",
    "\n",
    "            # The first block needs to take care of stride and filter size increase.\n",
    "            self._blocks.append(MBConvBlock(block_args, self._global_params))\n",
    "            if block_args.num_repeat > 1:\n",
    "                block_args = block_args._replace(input_filters=block_args.output_filters, stride=1)\n",
    "            for _ in range(block_args.num_repeat - 1):\n",
    "                self._blocks.append(MBConvBlock(block_args, self._global_params))\n",
    "\n",
    "        # Head\n",
    "        in_channels = block_args.output_filters  # output of final block\n",
    "        out_channels = round_filters(1280, self._global_params)\n",
    "        self._conv_head = Conv2dSamePadding(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self._bn1 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n",
    "\n",
    "        # Final linear layer\n",
    "        self._dropout = self._global_params.dropout_rate\n",
    "        self._fc = nn.Linear(out_channels, self._global_params.num_classes)\n",
    "\n",
    "            \n",
    "    def extract_features(self, inputs):\n",
    "        \"\"\" Returns output of the final convolution layer \"\"\"\n",
    "\n",
    "        # Stem\n",
    "        x = relu_fn(self._bn0(self._conv_stem(inputs)))\n",
    "\n",
    "        # Blocks\n",
    "        for idx, block in enumerate(self._blocks):\n",
    "            drop_connect_rate = self._global_params.drop_connect_rate\n",
    "            if drop_connect_rate:\n",
    "                drop_connect_rate *= float(idx) / len(self._blocks)\n",
    "            x = block(x) # , drop_connect_rate) # see https://github.com/tensorflow/tpu/issues/381\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\" Calls extract_features to extract features, applies final linear layer, and returns logits. \"\"\"\n",
    "\n",
    "        # Convolution layers\n",
    "        x = self.extract_features(inputs)\n",
    "\n",
    "        # Head\n",
    "        x = relu_fn(self._bn1(self._conv_head(x)))\n",
    "        x = F.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n",
    "        if self._dropout:\n",
    "            x = F.dropout(x, p=self._dropout, training=self.training)\n",
    "        x = self._fc(x)\n",
    "        return x\n",
    "\n",
    "    @classmethod\n",
    "    def from_name(cls, model_name, override_params=None):\n",
    "        cls._check_model_name_is_valid(model_name)\n",
    "        blocks_args, global_params = get_model_params(model_name, override_params)\n",
    "        return EfficientNet(blocks_args, global_params)\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_name):\n",
    "        model = EfficientNet.from_name(model_name)\n",
    "        #load_pretrained_weights(model, model_name)\n",
    "        return model\n",
    "\n",
    "    @classmethod\n",
    "    def get_image_size(cls, model_name):\n",
    "        cls._check_model_name_is_valid(model_name)\n",
    "        _, _, res, _ = efficientnet_params(model_name)\n",
    "        return res\n",
    "\n",
    "    @classmethod\n",
    "    def _check_model_name_is_valid(cls, model_name, also_need_pretrained_weights=False):\n",
    "        \"\"\" Validates model name. None that pretrained weights are only available for\n",
    "        the first four models (efficientnet-b{i} for i in 0,1,2,3) at the moment. \"\"\"\n",
    "        num_models = 4 if also_need_pretrained_weights else 8\n",
    "        valid_models = ['efficientnet_b'+str(i) for i in range(num_models)]\n",
    "        if model_name.replace('-','_') not in valid_models:\n",
    "            raise ValueError('model_name should be one of: ' + ', '.join(valid_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our clasifier stuff    \n",
    "src = (ImageList.from_csv(WORK/'image', Path('../../')/DATA/'train_curated.csv', folder='trn_curated', suffix='.jpg')\n",
    "                .split_by_rand_pct(0.1)\n",
    "                #.label_from_df(cols=list(df.columns[1:])))\n",
    "                .label_from_df(label_delim=','))\n",
    "\n",
    "data = (src.transform(tfms, size=128).databunch(bs=64).normalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNet.from_pretrained('efficientnet-b7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_score = partial(fbeta, thresh=0.2)\n",
    "learn = Learner(data, model, metrics=[f_score]).mixup(stack_y=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>fbeta</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.157103</td>\n",
       "      <td>0.168589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.089774</td>\n",
       "      <td>0.097450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.076116</td>\n",
       "      <td>0.087952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.071169</td>\n",
       "      <td>0.092147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.068069</td>\n",
       "      <td>0.090867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, 1e-2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
